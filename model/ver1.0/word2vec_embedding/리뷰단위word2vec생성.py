# -*- coding: utf-8 -*-
"""리뷰단위word2vec생성.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ktfqPlTbxBV-Z6Hz2wUMc5JiVBf93IDy

# 작업환경 생성
"""

# 라이브러리 로드, 데이터 로드, 간단 전처리(특수문자 제거)
import nltk
import pandas as pd
import re
from nltk.tokenize import word_tokenize, sent_tokenize
from gensim.models import Word2Vec
from sklearn.metrics.pairwise import  cosine_similarity
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

nltk.download('punkt')

#데이터 로드. (lematization, 특수문자 전체 제거)
df_train = pd.read_csv("https://raw.githubusercontent.com/SNMHZ/Drug_Recommendation/master/dataset/3/lem_test.csv")

#nan값 있는지 체크
print(df_train.isnull().values.any())
df_train = df_train.dropna(how='any')
print(df_train.isnull().values.any())

#컨디션에서 특수문자(special character) 제거
df_train['condition_scdrop']=df_train['condition'].apply(lambda x: re.sub('[^a-zA-Z]',' ',x))

"""# 데이터 확인"""

#데이터프레임 확인
df_train

#2개 리뷰 확인. 
print(df_train['review'][0])
print(df_train['review'][1])

"""# 컨디션 딕셔너리 생성(공백 제거용)

ex)

| original(key) | modified(value) |
| ------------- | --------------- |
| left ventricular dysfunction | leftventriculardysfunction |
| adhd | adhd |
| birth control | birthcontrol |
"""

spaced_condition=pd.read_csv('https://raw.githubusercontent.com/SNMHZ/Drug_Recommendation/master/dataset/spaced_condition.csv', index_col=0)
ori_con=spaced_condition['original'].unique()
mod_con=spaced_condition['modified'].unique()

for i in range(len(ori_con)):
    ori_con[i]=re.sub('[^a-zA-Z]',' ',ori_con[i])

for i in range(len(mod_con)):
    mod_con[i]=re.sub('[^a-zA-Z]',' ',mod_con[i])

con_dict={}
for i in range(len(mod_con)):
    con_dict[ori_con[i]]=mod_con[i]

"""# 학습을 위한 토큰 생성 (리뷰단위)"""

#각 리뷰마다 토큰으로 활용
tokenize_data = [word_tokenize(sentence) for sentence in df_train['review']]

#토큰 확인
print(tokenize_data[0])
print(tokenize_data[1])

"""# word2vec 모델 학습"""

##모델 학습
"""
하이퍼 파라미터
size : 300
window : 5
min_count : 5
workers : 4
sg : 0
"""
model = Word2Vec(sentences= tokenize_data, size=300, window=5, min_count=5, workers=4, sg=0)

model.save("reviewunit.model")

"""# 모델 테스트"""

#학습된 word2vec모델 테스트
print(type(model.wv.vectors))  #모델 weights table
print(model.wv.get_vector('side'))
print(model.wv.get_vector('side').shape)

print(len(df_train['condition_scdrop'].unique()))