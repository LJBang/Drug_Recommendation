{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SNMHZ/Drug_Recommendation/blob/master/MODEL2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq-c6jcIeXW3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import  cosine_similarity\n",
        "\n",
        "df_train = pd.read_csv(\"https://raw.githubusercontent.com/SNMHZ/Drug_Recommendation/master/dataset/lem_train.csv\", parse_dates=[\"date\"], infer_datetime_format=True)\n",
        "df_test = pd.read_csv(\"https://raw.githubusercontent.com/SNMHZ/Drug_Recommendation/master/dataset/lem_test.csv\", parse_dates=[\"date\"], infer_datetime_format=True)\n",
        "\n",
        "print(type(df_train['review']))\n",
        "\n",
        "#df_train['tokenize_review'] = word_tokenize(df_train['review'])\n",
        "\n",
        "print(df_train.isnull().values.any())\n",
        "print(df_test.isnull().values.any())\n",
        "\n",
        "print(len(df_train))\n",
        "print(len(df_test))\n",
        "\n",
        "df_train = df_train.dropna(how='any')\n",
        "df_test = df_test.dropna(how='any')\n",
        "\n",
        "print(df_train.isnull().values.any())\n",
        "print(df_test.isnull().values.any())\n",
        "\n",
        "print(len(df_train))\n",
        "print(len(df_test))\n",
        "print(df_train['review'][0])\n",
        "\n",
        "df_train['new'] = df_train['review'].str.cat(df_train['condition'], sep=' ')\n",
        "df_train['new'] = df_train['new'].str.lower()\n",
        "\n",
        "# to-do : 증상이 2단어 이상으로 이루어진것도 존재함. 이거 핸들링 해야 함\n",
        "\n",
        "tokenize_data = [word_tokenize(sentence) for sentence in df_train['new']]\n",
        "\n",
        "print(tokenize_data[:2])\n",
        "\n",
        "model = Word2Vec(sentences= tokenize_data, size=100, window=5, min_count=5, workers=4, sg=0)\n",
        "\n",
        "print(model.wv.vectors.shape)\n",
        "\n",
        "print(type(model.wv.most_similar('anxiety')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUjCL2OBgWyL"
      },
      "source": [
        "def predictCondition(data):\n",
        "    result = {}\n",
        "    # print(words)\n",
        "\n",
        "    for word in data:\n",
        "        try:\n",
        "            tmp = model.wv.most_similar(word, topn=100)\n",
        "            print(word)\n",
        "            # print(len(tmp))\n",
        "            # print(tmp)\n",
        "            result[word]= tmp\n",
        "        except:\n",
        "            print(word + \"not in here\\n\")\n",
        "    \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvxYezA6no-x"
      },
      "source": [
        "def predictCondition2dict(_predictCondition):\n",
        "  predict_dict = {}\n",
        "  for key, value in _predictCondition:\n",
        "    predict_dict[key] = value\n",
        "  return predict_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jQgAlU_nwWw"
      },
      "source": [
        "def predictCondition_concat(_dict_list):\n",
        "  sum_dict = {}\n",
        "  for _dict in _dict_list:\n",
        "    for key in _dict.keys():\n",
        "      if key in sum_dict:\n",
        "        sum_dict[key]+=_dict[key]\n",
        "      else:\n",
        "        sum_dict[key]=_dict[key]\n",
        "  return sum_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3VdoGDmpc5V"
      },
      "source": [
        "def predictConditionSum(data):\n",
        "  predict_res = predictCondition(data)\n",
        "  m_list = []\n",
        "  for key in predict_res:\n",
        "    m_list.append(predictCondition2dict(predict_res[key]))\n",
        "  return predictCondition_concat(m_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPntvwYaq7yi"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "n=WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def lemlem(msg):\n",
        "  msg=msg.replace(\"&#039;\", \"\")\n",
        "  msg=msg.replace(r'[^\\w\\d\\s]',' ')\n",
        "  msg=re.sub('[^a-zA-Z]',' ',msg)\n",
        "  low_msg = msg.lower().split()\n",
        "  stop_msg=[]\n",
        "  for w in low_msg: \n",
        "    if w not in stop_words: \n",
        "        stop_msg.append(w) \n",
        "  result=[n.lemmatize(w) for w in stop_msg]\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg-yhAJX5VgG"
      },
      "source": [
        "def isincheck(_str):\n",
        "  if len(set(only_condition.isin([_str.lower()])))==2:\n",
        "    return True\n",
        "  return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM6wXZ0zpe2X"
      },
      "source": [
        "while True:\n",
        "    msg = input(\"data : \")\n",
        "\n",
        "    tmp = predictConditionSum(lemlem(msg))\n",
        "\n",
        "    m_sorted_res = sorted(list(tmp.items()), key=lambda x:x[1], reverse=True)[:1000]\n",
        "\n",
        "    only_condition = pd.concat([df_train['condition'], df_test['condition']], axis=0)\n",
        "    only_condition = only_condition.drop_duplicates()\n",
        "    for i in only_condition.index:\n",
        "        only_condition[i] = only_condition[i].lower()\n",
        "    for i, res in enumerate(m_sorted_res):\n",
        "        if isincheck(res[0]):\n",
        "            print(i, res)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}